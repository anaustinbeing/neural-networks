{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "b1DiGnoDVWlW"
      ],
      "authorship_tag": "ABX9TyMYWiSHU35ioTHNaXTgn9AI",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/anaustinbeing/neural-networks/blob/main/backpropagation_(iris).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Implementing Backpropagation on network to train weights."
      ],
      "metadata": {
        "id": "wm0nhnBkwm-N"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Loading the dataset:"
      ],
      "metadata": {
        "id": "b1DiGnoDVWlW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "iris_dataset = load_iris()\n",
        "X = iris_dataset['data']\n",
        "y = iris_dataset['target']\n",
        "\n",
        "print(X.shape, y.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NFI2mF1_eq7a",
        "outputId": "f9355393-fa85-4212-a4e6-ecf0a32ad295"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(150, 4) (150,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Splitting the dataset into training and testing:"
      ],
      "metadata": {
        "id": "erTlUlJhVRPt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x_train, x_test, y_train, y_test = train_test_split(X, y, test_size=0.1)\n",
        "x_train.shape, y_train.shape, x_test.shape, y_test.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ahO9XGt1MJ7z",
        "outputId": "3570da57-d8d0-4953-bedf-c48120af449d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((135, 4), (135,), (15, 4), (15,))"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_train"
      ],
      "metadata": {
        "id": "qgO2nwUvzyRz",
        "outputId": "6996dbe9-3ecb-482b-d69d-81932da9bca4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1, 0, 1, 1, 2, 0, 1, 0, 0, 1, 1, 2, 2, 2, 1, 0, 0, 2, 1, 0, 0, 1,\n",
              "       2, 2, 1, 1, 0, 2, 2, 2, 2, 2, 1, 2, 2, 1, 0, 0, 2, 2, 0, 2, 1, 2,\n",
              "       0, 2, 0, 0, 1, 2, 0, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 1, 2, 0, 2,\n",
              "       0, 1, 0, 2, 2, 2, 0, 1, 0, 2, 0, 1, 2, 1, 1, 0, 0, 1, 1, 0, 2, 1,\n",
              "       1, 0, 0, 2, 2, 1, 0, 0, 1, 2, 0, 2, 2, 2, 1, 2, 2, 1, 2, 0, 0, 2,\n",
              "       0, 0, 2, 0, 1, 0, 2, 0, 0, 1, 0, 0, 2, 1, 0, 2, 2, 1, 1, 0, 1, 0,\n",
              "       1, 0, 2])"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Implementing the BackPropagation algorithm:"
      ],
      "metadata": {
        "id": "06C1T7YzVeCV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Training the network using the training data (`x_train` and `y_train`):"
      ],
      "metadata": {
        "id": "NMXiRmIzxDOH"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HSqjcMW1cnEm"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as pl\n",
        "%matplotlib inline\n",
        "#\n",
        "# function to compute the sigmoid\n",
        "sigmoid = lambda x: 1/(1 + np.exp(-x));\n",
        "#\n",
        "\n",
        "def backprop(W1, W2, X, D):\n",
        "    alpha = 0.9; # learning rate\n",
        "    N=135;\n",
        "    for k in range(0,N):\n",
        "        x = X[k, :].T; #inputs from training data\n",
        "        d = D[k]; # correct output from training data\n",
        "        ##########################\n",
        "        # forward propagation step\n",
        "        ##########################\n",
        "        # calculate the weighted sum of hidden node\n",
        "        v1 = np.dot(W1,x);\n",
        "        #pass the weighted sum to the activation function, this gives the outputs from hidden layer\n",
        "        y1 = sigmoid(v1);\n",
        "        #calculate the weighted sum of the output layer\n",
        "        v = np.dot(W2,y1);\n",
        "        # pass it to the activation function, this returns the output of the third layer\n",
        "        y = sigmoid(v);\n",
        "        #calculate the error, difference between correct output and computed output\n",
        "        d = [1, 0, 0] if d == 0 else [0, 1, 0] if d == 1 else [0, 0, 1]\n",
        "        e = d - y;\n",
        "\n",
        "        \n",
        "        #calculate delta, derivative of the activation function times the error\n",
        "        # note that ùúé‚Ä≤(ùë•)=ùúé(ùë•)‚àô(1‚àí ùúé(ùë•)) = y * (1-y)\n",
        "        delta = y*(1-y)*e; # element wise multiplication\n",
        "        ###########################\n",
        "        # Backward propagation step\n",
        "        ###########################\n",
        "        # propagate the output node delta, Œ¥, backward, and calculate the deltas of the hidden layer.\n",
        "        e1 = np.dot(W2.T, delta);\n",
        "        delta1 = y1*(1-y1)*e1;  # element wise multiplication\n",
        "        #\n",
        "        # Adjust the weights according to the learning rule\n",
        "        delta1.shape=(5,1) # column vector of deltas for the hidden layer\n",
        "        x.shape=(1,4) # row vector of the current input\n",
        "        dW1 = alpha*np.dot(delta1,x);\n",
        "        W1 = W1 + dW1;\n",
        "        #\n",
        "        delta.shape=(3,1)\n",
        "        y1.shape = (1, 5)\n",
        "        dW2 = alpha*np.dot(delta,y1);\n",
        "        W2 = W2 + dW2;\n",
        "    #\n",
        "    return W1, W2;\n",
        "#\n",
        "\n",
        "# initialize the weights between input layer and hidden layer\n",
        "W1 = 2*np.random.rand(5, 4) - 1;\n",
        "# initialize the weights between hidden layer and output layer\n",
        "W2 = 2*np.random.rand(3, 5) - 1;\n",
        "#\n",
        "# run the backprop algorithm to compute the weights\n",
        "for epoch in range(1, 1000): # train\n",
        "    print(W1.shape, W2.shape)\n",
        "    W1, W2 = backprop(W1, W2, x_train, y_train);\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Printing the weight vector values after training:"
      ],
      "metadata": {
        "id": "gj7BaKobVG9e"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "W1, W2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gcqT3GLF1cBy",
        "outputId": "6f1af53d-6bc8-46b9-a57a-5a756fbb0106"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([[-22.06251282, -15.34686957,  28.23229195,  29.80824248],\n",
              "        [ 21.39238287,  14.29741113, -21.42533827, -37.9360814 ],\n",
              "        [  0.5895355 ,   2.81921785,  -4.51679652,  -1.47606093],\n",
              "        [ -1.27612237,   0.19053071,  -0.42267135,   0.73349472],\n",
              "        [-11.98576905, -10.79213252,  13.70770794,  20.47061534]]),\n",
              " array([[-5.28511788, -5.16201004, 10.53377644,  0.78178917, -5.86125507],\n",
              "        [-3.41974898,  3.73617261, -8.92031611,  0.81532679, -2.40380057],\n",
              "        [ 3.42462065, -3.74400213, -2.86919184,  0.71624717,  2.4070266 ]]))"
            ]
          },
          "metadata": {},
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "`W1` is the weight vector between the input layer (4 neurons) and the hidden layer (5 neurons). The shape of `W1` is (5, 4).\n",
        "\n",
        "`W2` is the weight vector between the hidden layer (5 neurons) and the output layer (3 neurons). The shape of `W2` is (3, 5)."
      ],
      "metadata": {
        "id": "OU_jb7pBuCVc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Testing the network against test data:"
      ],
      "metadata": {
        "id": "Bgk-PutWVpjh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Testing on test data (`x_test` and `y_test`):"
      ],
      "metadata": {
        "id": "kPuqTMwauqkm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "outputs = []\n",
        "for k in range(x_test.shape[0]):\n",
        "    x = x_test[k, :].T;\n",
        "    d = y_test[k]; \n",
        "    v1 = np.dot(W1,x);\n",
        "    y1 = sigmoid(v1);\n",
        "    #calculate the weighted sum of the output layer\n",
        "    v = np.dot(W2,y1);\n",
        "    # pass it to the activation function, this returns the output of the third layer\n",
        "    y = sigmoid(v);\n",
        "    output = np.rint(y)\n",
        "    output_class = 0 if output[0] == 1 else 1 if output[1] == 1 else 2\n",
        "    print('\\nThe iris species is:', end=' ')\n",
        "    print('Setosa' if output_class == 0 \n",
        "          else 'Virginica' if output_class == 1 \n",
        "          else 'Versicolor' if output_class == 2 \n",
        "          else None, '\\nThe class value in the dataset is ', d)\n",
        "    outputs.append(output_class)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CMnKxyjohCDO",
        "outputId": "a5ace595-f624-4dbe-c28e-16bd0d09d5e6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "The iris species is: Versicolor \n",
            "The class value in the dataset is  2\n",
            "\n",
            "The iris species is: Versicolor \n",
            "The class value in the dataset is  2\n",
            "\n",
            "The iris species is: Versicolor \n",
            "The class value in the dataset is  2\n",
            "\n",
            "The iris species is: Setosa \n",
            "The class value in the dataset is  0\n",
            "\n",
            "The iris species is: Virginica \n",
            "The class value in the dataset is  1\n",
            "\n",
            "The iris species is: Versicolor \n",
            "The class value in the dataset is  2\n",
            "\n",
            "The iris species is: Virginica \n",
            "The class value in the dataset is  1\n",
            "\n",
            "The iris species is: Versicolor \n",
            "The class value in the dataset is  2\n",
            "\n",
            "The iris species is: Virginica \n",
            "The class value in the dataset is  2\n",
            "\n",
            "The iris species is: Virginica \n",
            "The class value in the dataset is  2\n",
            "\n",
            "The iris species is: Virginica \n",
            "The class value in the dataset is  1\n",
            "\n",
            "The iris species is: Setosa \n",
            "The class value in the dataset is  0\n",
            "\n",
            "The iris species is: Virginica \n",
            "The class value in the dataset is  1\n",
            "\n",
            "The iris species is: Virginica \n",
            "The class value in the dataset is  1\n",
            "\n",
            "The iris species is: Setosa \n",
            "The class value in the dataset is  0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "There are three neurons in the output layer. All layers use Sigmoid as the activation function. So the output of each neuron is a value between 0 and 1.\n",
        "\n",
        "We use `np.rint()` function on the output values to convert them to nearest whole number. And then if the output is `[1, 0, 0]`, the class is \"Setosa\". If the output is `[0, 1, 0]`, the class is \"Viriginica\". If the output is `[0, 0, 1]`, then the class is \"Vericolor\"."
      ],
      "metadata": {
        "id": "pQscWaeXwZW2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Finding how accurate the predictions are:"
      ],
      "metadata": {
        "id": "oOL06n4zUAac"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print('Predicted outputs: ', outputs)\n",
        "print('Test data target column values (original): ', y_test)\n",
        "print('Comparing the predicted output with test data target column values: ')\n",
        "print(outputs == y_test)"
      ],
      "metadata": {
        "id": "qCR3Mx40jlOD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6cd7d66b-35d7-43cc-cc09-8763178dfe53"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predicted outputs:  [2, 2, 2, 0, 1, 2, 1, 2, 1, 1, 1, 0, 1, 1, 0]\n",
            "Test data target column values (original):  [2 2 2 0 1 2 1 2 2 2 1 0 1 1 0]\n",
            "Comparing the predicted output with test data target column values: \n",
            "[ True  True  True  True  True  True  True  True False False  True  True\n",
            "  True  True  True]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We see the predicted ouputs and the original output values.\n",
        "\n",
        "Comparing, we see that 13 out of 15 predictions are correct while two are wrong. "
      ],
      "metadata": {
        "id": "TKE2b00xv89F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "accuracy_score(y_test, outputs)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "atN41ESiVwnr",
        "outputId": "042bb908-784c-418c-f5c5-f894aa0f2366"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8666666666666667"
            ]
          },
          "metadata": {},
          "execution_count": 65
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The accuracy is 86.66%"
      ],
      "metadata": {
        "id": "tJF5E21aWS9B"
      }
    }
  ]
}